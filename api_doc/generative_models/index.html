<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>grl.generative_models &mdash; GenerativeRL v0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=2fea6348"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="grl.neural_network" href="../neural_network/index.html" />
    <link rel="prev" title="grl.datasets" href="../datasets/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            GenerativeRL
          </a>
              <div class="version">
                0.0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/quick_start/index.html">Quick Start</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../agents/index.html">grl.agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/index.html">grl.algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/index.html">grl.datasets</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">grl.generative_models</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#diffusionmodel">DiffusionModel</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.generative_models.DiffusionModel"><code class="docutils literal notranslate"><span class="pre">DiffusionModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.__init__"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.data_prediction_function"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.data_prediction_function()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.dpo_loss"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.dpo_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.flow_matching_loss"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.flow_matching_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.forward_sample"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.forward_sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.noise_function"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.noise_function()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.sample"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.sample_forward_process"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.sample_forward_process()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.sample_forward_process_with_fixed_x"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.sample_forward_process_with_fixed_x()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.sample_with_fixed_x"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.sample_with_fixed_x()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.score_function"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.score_function()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.score_matching_loss"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.score_matching_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.DiffusionModel.velocity_function"><code class="docutils literal notranslate"><span class="pre">DiffusionModel.velocity_function()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#energyconditionaldiffusionmodel">EnergyConditionalDiffusionModel</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.__init__"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.data_prediction_function"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.data_prediction_function()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.data_prediction_function_with_energy_guidance"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.data_prediction_function_with_energy_guidance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.energy_guidance_loss"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.energy_guidance_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.flow_matching_loss"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.flow_matching_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.noise_function"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.noise_function()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.noise_function_with_energy_guidance"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.noise_function_with_energy_guidance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_forward_process"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.sample_forward_process()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_forward_process_with_fixed_x"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.sample_forward_process_with_fixed_x()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_with_fixed_x"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.sample_with_fixed_x()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_with_fixed_x_without_energy_guidance"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.sample_with_fixed_x_without_energy_guidance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_without_energy_guidance"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.sample_without_energy_guidance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.score_function"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.score_function()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.score_function_with_energy_guidance"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.score_function_with_energy_guidance()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.score_matching_loss"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.score_matching_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.EnergyConditionalDiffusionModel.velocity_function"><code class="docutils literal notranslate"><span class="pre">EnergyConditionalDiffusionModel.velocity_function()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#independentconditionalflowmodel">IndependentConditionalFlowModel</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.generative_models.IndependentConditionalFlowModel"><code class="docutils literal notranslate"><span class="pre">IndependentConditionalFlowModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.IndependentConditionalFlowModel.__init__"><code class="docutils literal notranslate"><span class="pre">IndependentConditionalFlowModel.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.IndependentConditionalFlowModel.flow_matching_loss"><code class="docutils literal notranslate"><span class="pre">IndependentConditionalFlowModel.flow_matching_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.IndependentConditionalFlowModel.sample"><code class="docutils literal notranslate"><span class="pre">IndependentConditionalFlowModel.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.IndependentConditionalFlowModel.sample_forward_process"><code class="docutils literal notranslate"><span class="pre">IndependentConditionalFlowModel.sample_forward_process()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#optimaltransportconditionalflowmodel">OptimalTransportConditionalFlowModel</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.generative_models.OptimalTransportConditionalFlowModel"><code class="docutils literal notranslate"><span class="pre">OptimalTransportConditionalFlowModel</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.OptimalTransportConditionalFlowModel.__init__"><code class="docutils literal notranslate"><span class="pre">OptimalTransportConditionalFlowModel.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.OptimalTransportConditionalFlowModel.flow_matching_loss"><code class="docutils literal notranslate"><span class="pre">OptimalTransportConditionalFlowModel.flow_matching_loss()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.OptimalTransportConditionalFlowModel.flow_matching_loss_small_batch_OT_plan"><code class="docutils literal notranslate"><span class="pre">OptimalTransportConditionalFlowModel.flow_matching_loss_small_batch_OT_plan()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.OptimalTransportConditionalFlowModel.sample"><code class="docutils literal notranslate"><span class="pre">OptimalTransportConditionalFlowModel.sample()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.generative_models.OptimalTransportConditionalFlowModel.sample_forward_process"><code class="docutils literal notranslate"><span class="pre">OptimalTransportConditionalFlowModel.sample_forward_process()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../neural_network/index.html">grl.neural_network</a></li>
<li class="toctree-l1"><a class="reference internal" href="../numerical_methods/index.html">grl.numerical_methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rl_modules/index.html">grl.rl_modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/index.html">grl.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">GenerativeRL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">grl.generative_models</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_doc/generative_models/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-grl.generative_models">
<span id="grl-generative-models"></span><h1>grl.generative_models<a class="headerlink" href="#module-grl.generative_models" title="Link to this heading"></a></h1>
<section id="diffusionmodel">
<h2>DiffusionModel<a class="headerlink" href="#diffusionmodel" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.generative_models.</span></span><span class="sig-name descname"><span class="pre">DiffusionModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>General diffusion model class that supports various types of continuous-time diffusion paths, which supports sampling, computing score function and velocity function.
It can be modeled via score function, noise function, velocity function, or data prediction function.
Both score matching loss and flow matching loss are supported.</p>
</dd>
<dt>Interfaces:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">sample</span></code>, <code class="docutils literal notranslate"><span class="pre">score_function</span></code>, <code class="docutils literal notranslate"><span class="pre">score_matching_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">velocity_function</span></code>, <code class="docutils literal notranslate"><span class="pre">flow_matching_loss</span></code>.</p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialization of Diffusion Model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.data_prediction_function">
<span class="sig-name descname"><span class="pre">data_prediction_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.data_prediction_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.data_prediction_function" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Return data prediction function of the model at time t given the initial state.</p>
<div class="math notranslate nohighlight">
\[\frac{- \sigma(t) x_t + \sigma^2(t) \nabla_{x_t} \log p_{\theta}(x_t)}{s(t)}\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.dpo_loss">
<span class="sig-name descname"><span class="pre">dpo_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">ref_dm</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">data</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">beta</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.dpo_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.dpo_loss" title="Link to this definition"></a></dt>
<dd><dl class="field-list simple">
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
<dl class="simple">
<dt>Overview:</dt><dd><p>The loss function for training the diffusion process by Direct Policy Optimization (DPO).
This is an in-development feature and is not recommended for general use.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.flow_matching_loss">
<span class="sig-name descname"><span class="pre">flow_matching_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.flow_matching_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.flow_matching_loss" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the flow matching loss function of the model given the initial state and the condition.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>average</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to average the loss across the batch.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.forward_sample">
<span class="sig-name descname"><span class="pre">forward_sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_span</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.forward_sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.forward_sample" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Use forward path of the diffusion model given the sampled x. Note that this is not the reverse process, and thus is not designed for sampling form the diffusion model.
Rather, it is used for encode a sampled x to the latent space.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.noise_function">
<span class="sig-name descname"><span class="pre">noise_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.noise_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.noise_function" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Return noise function of the model at time t given the initial state.</p>
<div class="math notranslate nohighlight">
\[- \sigma(t) \nabla_{x_t} \log p_{\theta}(x_t)\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.sample" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model, return the final state.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.sample_forward_process">
<span class="sig-name descname"><span class="pre">sample_forward_process</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.sample_forward_process"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.sample_forward_process" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model, return all intermediate states.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – An extra batch size used for repeated sampling with the same initial state.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((T, N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((T, B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((T, B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((T, D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.sample_forward_process_with_fixed_x">
<span class="sig-name descname"><span class="pre">sample_forward_process_with_fixed_x</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fixed_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.sample_forward_process_with_fixed_x"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.sample_forward_process_with_fixed_x" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model with fixed x, return all intermediate states.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fixed_x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed x.</p></li>
<li><p><strong>fixed_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed mask.</p></li>
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>fixed_x: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
fixed_mask: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the mask, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((T, N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((T, B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((T, B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((T, D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.sample_with_fixed_x">
<span class="sig-name descname"><span class="pre">sample_with_fixed_x</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fixed_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.sample_with_fixed_x"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.sample_with_fixed_x" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model with fixed x, return the final state.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fixed_x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed x.</p></li>
<li><p><strong>fixed_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed mask.</p></li>
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>fixed_x: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
fixed_mask: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the mask, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((D,)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.score_function">
<span class="sig-name descname"><span class="pre">score_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.score_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.score_function" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Return score function of the model at time t given the initial state, which is the gradient of the log-likelihood.</p>
<div class="math notranslate nohighlight">
\[\nabla_{x_t} \log p_{\theta}(x_t)\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.score_matching_loss">
<span class="sig-name descname"><span class="pre">score_matching_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighting_scheme</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.score_matching_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.score_matching_loss" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The loss function for training unconditional diffusion model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>weighting_scheme</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>) – The weighting scheme for score matching loss, which can be “maximum_likelihood” or “vanilla”.</p></li>
<li><p><strong>..note::</strong> – <ul>
<li><p>“maximum_likelihood”: The weighting scheme is based on the maximum likelihood estimation. Refer to the paper “Maximum Likelihood Training of Score-Based Diffusion Models” for more details. The weight <span class="math notranslate nohighlight">\(\lambda(t)\)</span> is denoted as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\lambda(t) = g^2(t)\]</div>
<p>for numerical stability, we use Monte Carlo sampling to approximate the integral of <span class="math notranslate nohighlight">\(\lambda(t)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\lambda(t) = g^2(t) = p(t)\sigma^2(t)\]</div>
</div></blockquote>
</li>
<li><p>“vanilla”: The weighting scheme is based on the vanilla score matching, which balances the MSE loss by scaling the model output to the noise value. Refer to the paper “Score-Based Generative Modeling through Stochastic Differential Equations” for more details. The weight <span class="math notranslate nohighlight">\(\lambda(t)\)</span> is denoted as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\lambda(t) = \sigma^2(t)\]</div>
</div></blockquote>
</li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.DiffusionModel.velocity_function">
<span class="sig-name descname"><span class="pre">velocity_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/diffusion_model.html#DiffusionModel.velocity_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.DiffusionModel.velocity_function" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Return velocity of the model at time t given the initial state.</p>
<div class="math notranslate nohighlight">
\[v_{\theta}(t, x)\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state at time t.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="energyconditionaldiffusionmodel">
<h2>EnergyConditionalDiffusionModel<a class="headerlink" href="#energyconditionaldiffusionmodel" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.generative_models.</span></span><span class="sig-name descname"><span class="pre">EnergyConditionalDiffusionModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">energy_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Energy Conditional Diffusion Model, which is a diffusion model conditioned on energy.</p>
<div class="math notranslate nohighlight">
\[p_{\text{E}}(x|c)\sim \frac{\exp{\mathcal{E}(x,c)}}{Z(c)}p(x|c)\]</div>
</dd>
<dt>Interfaces:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">sample</span></code>, <code class="docutils literal notranslate"><span class="pre">sample_without_energy_guidance</span></code>, <code class="docutils literal notranslate"><span class="pre">sample_forward_process</span></code>, <code class="docutils literal notranslate"><span class="pre">score_function</span></code>, <code class="docutils literal notranslate"><span class="pre">score_function_with_energy_guidance</span></code>, <code class="docutils literal notranslate"><span class="pre">score_matching_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">velocity_function</span></code>, <code class="docutils literal notranslate"><span class="pre">flow_matching_loss</span></code>, <code class="docutils literal notranslate"><span class="pre">energy_guidance_loss</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">energy_model</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialization of Energy Conditional Diffusion Model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration.</p></li>
<li><p><strong>energy_model</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.nn.Module,</span> <span class="pre">torch.nn.ModuleDict]</span></code>) – The energy model.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.data_prediction_function">
<span class="sig-name descname"><span class="pre">data_prediction_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.data_prediction_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.data_prediction_function" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Return data prediction function of the model at time t given the initial state.</p>
<div class="math notranslate nohighlight">
\[\frac{- \sigma(t) x_t + \sigma^2(t) \nabla_{x_t} \log p_{\theta}(x_t)}{s(t)}\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.data_prediction_function_with_energy_guidance">
<span class="sig-name descname"><span class="pre">data_prediction_function_with_energy_guidance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">guidance_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.data_prediction_function_with_energy_guidance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.data_prediction_function_with_energy_guidance" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The data prediction function for energy guidance.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>guidance_scale</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The scale of guidance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The score function.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.energy_guidance_loss">
<span class="sig-name descname"><span class="pre">energy_guidance_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.energy_guidance_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.energy_guidance_loss" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The loss function for training Energy Guidance, CEP guidance method, as proposed in the paper             “Contrastive Energy Prediction for Exact Energy-Guided Diffusion Sampling in Offline Reinforcement Learning”</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.flow_matching_loss">
<span class="sig-name descname"><span class="pre">flow_matching_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.flow_matching_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.flow_matching_loss" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the flow matching loss function of the model given the initial state and the condition.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>average</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to average the loss across the batch.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.noise_function">
<span class="sig-name descname"><span class="pre">noise_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.noise_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.noise_function" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Return noise function of the model at time t given the initial state.</p>
<div class="math notranslate nohighlight">
\[- \sigma(t) \nabla_{x_t} \log p_{\theta}(x_t)\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.noise_function_with_energy_guidance">
<span class="sig-name descname"><span class="pre">noise_function_with_energy_guidance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">guidance_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.noise_function_with_energy_guidance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.noise_function_with_energy_guidance" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The noise function for energy guidance.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>guidance_scale</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The scale of guidance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The nose function.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>noise (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">guidance_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Sample from the energy conditioned diffusion model by using score function.</p>
<div class="math notranslate nohighlight">
\[\nabla p_{\text{E}}(x|c) = \nabla p(x|c) + \nabla \mathcal{E}(x,c,t)\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>guidance_scale</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The scale of guidance.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.sample_forward_process">
<span class="sig-name descname"><span class="pre">sample_forward_process</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">guidance_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.sample_forward_process"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_forward_process" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>guidance_scale</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The scale of guidance.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.sample_forward_process_with_fixed_x">
<span class="sig-name descname"><span class="pre">sample_forward_process_with_fixed_x</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fixed_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">guidance_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.sample_forward_process_with_fixed_x"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_forward_process_with_fixed_x" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model with fixed x.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fixed_x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed x.</p></li>
<li><p><strong>fixed_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed mask.</p></li>
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>guidance_scale</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The scale of guidance.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>fixed_x: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
fixed_mask: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the mask, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((T, N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((T, B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((T, B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((T, D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.sample_with_fixed_x">
<span class="sig-name descname"><span class="pre">sample_with_fixed_x</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fixed_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">guidance_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.sample_with_fixed_x"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_with_fixed_x" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model with fixed x.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fixed_x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed x.</p></li>
<li><p><strong>fixed_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed mask.</p></li>
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>guidance_scale</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The scale of guidance.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>fixed_x: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
fixed_mask: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the mask, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((D,)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.sample_with_fixed_x_without_energy_guidance">
<span class="sig-name descname"><span class="pre">sample_with_fixed_x_without_energy_guidance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">fixed_x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">fixed_mask</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.sample_with_fixed_x_without_energy_guidance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_with_fixed_x_without_energy_guidance" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model with fixed x without energy guidance.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>fixed_x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed x.</p></li>
<li><p><strong>fixed_mask</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The fixed mask.</p></li>
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>fixed_x: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
fixed_mask: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the mask, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((D,)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.sample_without_energy_guidance">
<span class="sig-name descname"><span class="pre">sample_without_energy_guidance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.sample_without_energy_guidance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.sample_without_energy_guidance" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model without energy guidance.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((T, N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((T, B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((T, B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((T, D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.score_function">
<span class="sig-name descname"><span class="pre">score_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.score_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.score_function" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Return score function of the model at time t given the initial state, which is the gradient of the log-likelihood.</p>
<div class="math notranslate nohighlight">
\[\nabla_{x_t} \log p_{\theta}(x_t)\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.score_function_with_energy_guidance">
<span class="sig-name descname"><span class="pre">score_function_with_energy_guidance</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">guidance_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.score_function_with_energy_guidance"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.score_function_with_energy_guidance" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The score function for energy guidance.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>guidance_scale</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The scale of guidance.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The score function.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>score (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.score_matching_loss">
<span class="sig-name descname"><span class="pre">score_matching_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">weighting_scheme</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.score_matching_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.score_matching_loss" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The loss function for training unconditional diffusion model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>weighting_scheme</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">str</span></code>) – The weighting scheme for score matching loss, which can be “maximum_likelihood” or “vanilla”.</p></li>
<li><p><strong>average</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to average the loss across the batch.</p></li>
<li><p><strong>..note::</strong> – <ul>
<li><p>“maximum_likelihood”: The weighting scheme is based on the maximum likelihood estimation. Refer to the paper “Maximum Likelihood Training of Score-Based Diffusion Models” for more details. The weight <span class="math notranslate nohighlight">\(\lambda(t)\)</span> is denoted as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\lambda(t) = g^2(t)\]</div>
<p>for numerical stability, we use Monte Carlo sampling to approximate the integral of <span class="math notranslate nohighlight">\(\lambda(t)\)</span>.</p>
<div class="math notranslate nohighlight">
\[\lambda(t) = g^2(t) = p(t)\sigma^2(t)\]</div>
</div></blockquote>
</li>
<li><p>“vanilla”: The weighting scheme is based on the vanilla score matching, which balances the MSE loss by scaling the model output to the noise value. Refer to the paper “Score-Based Generative Modeling through Stochastic Differential Equations” for more details. The weight <span class="math notranslate nohighlight">\(\lambda(t)\)</span> is denoted as:</p>
<blockquote>
<div><div class="math notranslate nohighlight">
\[\lambda(t) = \sigma^2(t)\]</div>
</div></blockquote>
</li>
</ul>
</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.EnergyConditionalDiffusionModel.velocity_function">
<span class="sig-name descname"><span class="pre">velocity_function</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/diffusion_model/energy_conditional_diffusion_model.html#EnergyConditionalDiffusionModel.velocity_function"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.EnergyConditionalDiffusionModel.velocity_function" title="Link to this definition"></a></dt>
<dd><dl>
<dt>Overview:</dt><dd><p>Return velocity of the model at time t given the initial state.</p>
<div class="math notranslate nohighlight">
\[v_{\theta}(t, x)\]</div>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input time.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state at time t.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-data docutils literal notranslate"><span class="pre">Union</span></code>[<code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">TensorDict</span></code>, <code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code>]</span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="independentconditionalflowmodel">
<h2>IndependentConditionalFlowModel<a class="headerlink" href="#independentconditionalflowmodel" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.generative_models.IndependentConditionalFlowModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.generative_models.</span></span><span class="sig-name descname"><span class="pre">IndependentConditionalFlowModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/independent_conditional_flow_model.html#IndependentConditionalFlowModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.IndependentConditionalFlowModel" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The independent conditional flow model, which is a flow model with independent conditional probability paths.</p>
</dd>
<dt>Interfaces:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">get_type</span></code>, <code class="docutils literal notranslate"><span class="pre">sample</span></code>, <code class="docutils literal notranslate"><span class="pre">sample_forward_process</span></code>, <code class="docutils literal notranslate"><span class="pre">flow_matching_loss</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.IndependentConditionalFlowModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/independent_conditional_flow_model.html#IndependentConditionalFlowModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.IndependentConditionalFlowModel.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize the model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.IndependentConditionalFlowModel.flow_matching_loss">
<span class="sig-name descname"><span class="pre">flow_matching_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/independent_conditional_flow_model.html#IndependentConditionalFlowModel.flow_matching_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.IndependentConditionalFlowModel.flow_matching_loss" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the flow matching loss function of the model given the initial state and the condition.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state.</p></li>
<li><p><strong>x1</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The final state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The condition for the flow matching loss.</p></li>
<li><p><strong>average</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to average the loss across the batch.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.IndependentConditionalFlowModel.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/independent_conditional_flow_model.html#IndependentConditionalFlowModel.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.IndependentConditionalFlowModel.sample" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the model, return the final state.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.IndependentConditionalFlowModel.sample_forward_process">
<span class="sig-name descname"><span class="pre">sample_forward_process</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/independent_conditional_flow_model.html#IndependentConditionalFlowModel.sample_forward_process"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.IndependentConditionalFlowModel.sample_forward_process" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the diffusion model, return all intermediate states.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – An extra batch size used for repeated sampling with the same initial state.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((T, N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((T, B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((T, B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((T, D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="optimaltransportconditionalflowmodel">
<h2>OptimalTransportConditionalFlowModel<a class="headerlink" href="#optimaltransportconditionalflowmodel" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.generative_models.OptimalTransportConditionalFlowModel">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.generative_models.</span></span><span class="sig-name descname"><span class="pre">OptimalTransportConditionalFlowModel</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/optimal_transport_conditional_flow_model.html#OptimalTransportConditionalFlowModel"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.OptimalTransportConditionalFlowModel" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>The optimal transport conditional flow model, which is based on an optimal transport plan between two distributions.</p>
</dd>
<dt>Interfaces:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">get_type</span></code>, <code class="docutils literal notranslate"><span class="pre">sample</span></code>, <code class="docutils literal notranslate"><span class="pre">sample_forward_process</span></code>, <code class="docutils literal notranslate"><span class="pre">flow_matching_loss</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.OptimalTransportConditionalFlowModel.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">config</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/optimal_transport_conditional_flow_model.html#OptimalTransportConditionalFlowModel.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.OptimalTransportConditionalFlowModel.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize the model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>config</strong> (<em>-</em>) – The configuration of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.OptimalTransportConditionalFlowModel.flow_matching_loss">
<span class="sig-name descname"><span class="pre">flow_matching_loss</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/optimal_transport_conditional_flow_model.html#OptimalTransportConditionalFlowModel.flow_matching_loss"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.OptimalTransportConditionalFlowModel.flow_matching_loss" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the flow matching loss function of the model given the initial state and the condition, using the optimal transport plan to match samples from two distributions.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.OptimalTransportConditionalFlowModel.flow_matching_loss_small_batch_OT_plan">
<span class="sig-name descname"><span class="pre">flow_matching_loss_small_batch_OT_plan</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">average</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/optimal_transport_conditional_flow_model.html#OptimalTransportConditionalFlowModel.flow_matching_loss_small_batch_OT_plan"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.OptimalTransportConditionalFlowModel.flow_matching_loss_small_batch_OT_plan" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the flow matching loss function of the model given the initial state and the condition, using the optimal transport plan for small batch size to accelerate the computation.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input state.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.OptimalTransportConditionalFlowModel.sample">
<span class="sig-name descname"><span class="pre">sample</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/optimal_transport_conditional_flow_model.html#OptimalTransportConditionalFlowModel.sample"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.OptimalTransportConditionalFlowModel.sample" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the model, return the final state.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – The batch size.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.generative_models.OptimalTransportConditionalFlowModel.sample_forward_process">
<span class="sig-name descname"><span class="pre">sample_forward_process</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t_span</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">batch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x_0</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">with_grad</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">solver_config</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/generative_models/conditional_flow_model/optimal_transport_conditional_flow_model.html#OptimalTransportConditionalFlowModel.sample_forward_process"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.generative_models.OptimalTransportConditionalFlowModel.sample_forward_process" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Sample from the model, return all intermediate states.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t_span</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The time span.</p></li>
<li><p><strong>batch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Size,</span> <span class="pre">int,</span> <span class="pre">Tuple[int],</span> <span class="pre">List[int]]</span></code>) – An extra batch size used for repeated sampling with the same initial state.</p></li>
<li><p><strong>x_0</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The initial state, if not provided, it will be sampled from the Gaussian distribution.</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>) – The input condition.</p></li>
<li><p><strong>with_grad</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to return the gradient.</p></li>
<li><p><strong>solver_config</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">EasyDict</span></code>) – The configuration of the solver.</p></li>
</ul>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The sampled result.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict,</span> <span class="pre">treetensor.torch.Tensor]</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>t_span: <span class="math notranslate nohighlight">\((T)\)</span>, where <span class="math notranslate nohighlight">\(T\)</span> is the number of time steps.
batch_size: <span class="math notranslate nohighlight">\((B)\)</span>, where <span class="math notranslate nohighlight">\(B\)</span> is the batch size of data, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((B1, B2)\)</span>.
x_0: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the state, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
condition: <span class="math notranslate nohighlight">\((N, D)\)</span>, where <span class="math notranslate nohighlight">\(N\)</span> is the batch size of data and <span class="math notranslate nohighlight">\(D\)</span> is the dimension of the condition, which could be a scalar or a tensor such as <span class="math notranslate nohighlight">\((D1, D2)\)</span>.
x: <span class="math notranslate nohighlight">\((T, N, D)\)</span>, if extra batch size <span class="math notranslate nohighlight">\(B\)</span> is provided, the shape will be <span class="math notranslate nohighlight">\((T, B, N, D)\)</span>. If x_0 is not provided, the shape will be <span class="math notranslate nohighlight">\((T, B, D)\)</span>. If x_0 and condition are not provided, the shape will be <span class="math notranslate nohighlight">\((T, D)\)</span>.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../datasets/index.html" class="btn btn-neutral float-left" title="grl.datasets" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../neural_network/index.html" class="btn btn-neutral float-right" title="grl.neural_network" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, OpenDILab Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>