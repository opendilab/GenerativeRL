<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>grl.neural_network &mdash; GenerativeRL v0.0.1 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../_static/pygments.css?v=80d5e7a1" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/theme.css?v=19f00094" />
      <link rel="stylesheet" type="text/css" href="../../_static/graphviz.css?v=fd3f3429" />
      <link rel="stylesheet" type="text/css" href="../../_static/css/custom.css" />

  
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../_static/documentation_options.js?v=2fea6348"></script>
        <script src="../../_static/doctools.js?v=9a2dae69"></script>
        <script src="../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="grl.numerical_methods" href="../numerical_methods/index.html" />
    <link rel="prev" title="grl.generative_models" href="../generative_models/index.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../index.html" class="icon icon-home">
            GenerativeRL
          </a>
              <div class="version">
                0.0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Tutorials</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/installation/index.html">Installation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../tutorials/quick_start/index.html">Quick Start</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">API Documentation</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../agents/index.html">grl.agents</a></li>
<li class="toctree-l1"><a class="reference internal" href="../algorithms/index.html">grl.algorithms</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/index.html">grl.datasets</a></li>
<li class="toctree-l1"><a class="reference internal" href="../generative_models/index.html">grl.generative_models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">grl.neural_network</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#concatenatelayer">ConcatenateLayer</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.neural_network.ConcatenateLayer"><code class="docutils literal notranslate"><span class="pre">ConcatenateLayer</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.ConcatenateLayer.__init__"><code class="docutils literal notranslate"><span class="pre">ConcatenateLayer.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.ConcatenateLayer.forward"><code class="docutils literal notranslate"><span class="pre">ConcatenateLayer.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#multilayerperceptron">MultiLayerPerceptron</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.neural_network.MultiLayerPerceptron"><code class="docutils literal notranslate"><span class="pre">MultiLayerPerceptron</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.MultiLayerPerceptron.__init__"><code class="docutils literal notranslate"><span class="pre">MultiLayerPerceptron.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.MultiLayerPerceptron.forward"><code class="docutils literal notranslate"><span class="pre">MultiLayerPerceptron.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#concatenatemlp">ConcatenateMLP</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.neural_network.ConcatenateMLP"><code class="docutils literal notranslate"><span class="pre">ConcatenateMLP</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.ConcatenateMLP.__init__"><code class="docutils literal notranslate"><span class="pre">ConcatenateMLP.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.ConcatenateMLP.forward"><code class="docutils literal notranslate"><span class="pre">ConcatenateMLP.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#temporalspatialresidualnet">TemporalSpatialResidualNet</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.neural_network.TemporalSpatialResidualNet"><code class="docutils literal notranslate"><span class="pre">TemporalSpatialResidualNet</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.TemporalSpatialResidualNet.__init__"><code class="docutils literal notranslate"><span class="pre">TemporalSpatialResidualNet.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.TemporalSpatialResidualNet.forward"><code class="docutils literal notranslate"><span class="pre">TemporalSpatialResidualNet.forward()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dit">DiT</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.neural_network.DiT"><code class="docutils literal notranslate"><span class="pre">DiT</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT.__init__"><code class="docutils literal notranslate"><span class="pre">DiT.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT.forward"><code class="docutils literal notranslate"><span class="pre">DiT.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT.forward_with_cfg"><code class="docutils literal notranslate"><span class="pre">DiT.forward_with_cfg()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT.initialize_weights"><code class="docutils literal notranslate"><span class="pre">DiT.initialize_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT.unpatchify"><code class="docutils literal notranslate"><span class="pre">DiT.unpatchify()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dit1d">DiT1D</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.neural_network.DiT1D"><code class="docutils literal notranslate"><span class="pre">DiT1D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT1D.__init__"><code class="docutils literal notranslate"><span class="pre">DiT1D.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT1D.forward"><code class="docutils literal notranslate"><span class="pre">DiT1D.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT1D.initialize_weights"><code class="docutils literal notranslate"><span class="pre">DiT1D.initialize_weights()</span></code></a></li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dit2d">DiT2D</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.neural_network.DiT2D"><code class="docutils literal notranslate"><span class="pre">DiT2D</span></code></a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="#dit3d">DiT3D</a><ul>
<li class="toctree-l3"><a class="reference internal" href="#grl.neural_network.DiT3D"><code class="docutils literal notranslate"><span class="pre">DiT3D</span></code></a><ul>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT3D.__init__"><code class="docutils literal notranslate"><span class="pre">DiT3D.__init__()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT3D.forward"><code class="docutils literal notranslate"><span class="pre">DiT3D.forward()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT3D.initialize_weights"><code class="docutils literal notranslate"><span class="pre">DiT3D.initialize_weights()</span></code></a></li>
<li class="toctree-l4"><a class="reference internal" href="#grl.neural_network.DiT3D.unpatchify"><code class="docutils literal notranslate"><span class="pre">DiT3D.unpatchify()</span></code></a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../numerical_methods/index.html">grl.numerical_methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../rl_modules/index.html">grl.rl_modules</a></li>
<li class="toctree-l1"><a class="reference internal" href="../utils/index.html">grl.utils</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">GenerativeRL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">grl.neural_network</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../../_sources/api_doc/neural_network/index.rst.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="module-grl.neural_network">
<span id="grl-neural-network"></span><h1>grl.neural_network<a class="headerlink" href="#module-grl.neural_network" title="Link to this heading"></a></h1>
<section id="concatenatelayer">
<h2>ConcatenateLayer<a class="headerlink" href="#concatenatelayer" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.neural_network.ConcatenateLayer">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.neural_network.</span></span><span class="sig-name descname"><span class="pre">ConcatenateLayer</span></span><a class="reference internal" href="../../_modules/grl/neural_network.html#ConcatenateLayer"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.ConcatenateLayer" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Concatenate the input tensors along the last dimension.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">forward</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.ConcatenateLayer.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#ConcatenateLayer.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.ConcatenateLayer.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initiate the concatenate layer.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.ConcatenateLayer.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#ConcatenateLayer.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.ConcatenateLayer.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the concatenated tensor.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>-</em>) – The input tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="multilayerperceptron">
<h2>MultiLayerPerceptron<a class="headerlink" href="#multilayerperceptron" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.neural_network.MultiLayerPerceptron">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.neural_network.</span></span><span class="sig-name descname"><span class="pre">MultiLayerPerceptron</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layernorm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shrink</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#MultiLayerPerceptron"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.MultiLayerPerceptron" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Multi-layer perceptron using fully-connected layers with activation, dropout, and layernorm.
x -&gt; fc1 -&gt; act1 -&gt; dropout -&gt; layernorm -&gt; … -&gt; fcn -&gt; actn -&gt; out</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">forward</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.MultiLayerPerceptron.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">activation</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">dropout</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">layernorm</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">final_activation</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">shrink</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#MultiLayerPerceptron.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.MultiLayerPerceptron.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initiate the multi-layer perceptron.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_sizes</strong> (<em>-</em>) – The list of hidden sizes.</p></li>
<li><p><strong>output_size</strong> (<em>-</em>) – The number of channels in the output tensor.</p></li>
<li><p><strong>activation</strong> (<em>-</em>) – The optional activation function.</p></li>
<li><p><strong>dropout</strong> (<em>-</em>) – Probability of an element to be zeroed in the dropout. Default is None.</p></li>
<li><p><strong>layernorm</strong> (<em>-</em>) – Whether to use layernorm in the fully-connected block. Default is False.</p></li>
<li><p><strong>final_activation</strong> (<em>-</em>) – The optional activation function in the final layer. Default is None.</p></li>
<li><p><strong>scale</strong> (<em>-</em>) – The scale of the output tensor. Default is None.</p></li>
<li><p><strong>shrink</strong> (<em>-</em>) – The shrinkage factor of the output tensor. Default is None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.MultiLayerPerceptron.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#MultiLayerPerceptron.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.MultiLayerPerceptron.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the output of the multi-layer perceptron.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>-</em>) – The input tensor.</p>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="concatenatemlp">
<h2>ConcatenateMLP<a class="headerlink" href="#concatenatemlp" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.neural_network.ConcatenateMLP">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.neural_network.</span></span><span class="sig-name descname"><span class="pre">ConcatenateMLP</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#ConcatenateMLP"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.ConcatenateMLP" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Concatenate the input tensors along the last dimension and then pass through a multi-layer perceptron.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">forward</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.ConcatenateMLP.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">**</span></span><span class="n"><span class="pre">kwargs</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#ConcatenateMLP.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.ConcatenateMLP.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initiate the concatenate MLP.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>**kwargs</strong> (<em>-</em>) – <p>The keyword arguments for the multi-layer perceptron.</p>
</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.ConcatenateMLP.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="o"><span class="pre">*</span></span><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#ConcatenateMLP.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.ConcatenateMLP.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the output of the concatenate MLP.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<em>-</em>) – The input tensor.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="temporalspatialresidualnet">
<h2>TemporalSpatialResidualNet<a class="headerlink" href="#temporalspatialresidualnet" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.neural_network.TemporalSpatialResidualNet">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.neural_network.</span></span><span class="sig-name descname"><span class="pre">TemporalSpatialResidualNet</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_hidden_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_condition_hidden_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#TemporalSpatialResidualNet"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.TemporalSpatialResidualNet" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Temporal Spatial Residual Network using multiple TemporalSpatialResBlock.</p>
</dd>
<dt>Interface:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">forward</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.TemporalSpatialResidualNet.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">hidden_sizes</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">output_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_dim</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">input_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_hidden_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">t_condition_hidden_dim</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#TemporalSpatialResidualNet.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.TemporalSpatialResidualNet.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initiate the temporal spatial residual network.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>hidden_sizes</strong> (<em>-</em>) – The list of hidden sizes.</p></li>
<li><p><strong>output_dim</strong> (<em>-</em>) – The number of channels in the output tensor.</p></li>
<li><p><strong>t_dim</strong> (<em>-</em>) – The dimension of the temporal input.</p></li>
<li><p><strong>condition_dim</strong> (<em>-</em>) – The number of channels in the condition tensor. Default is None.</p></li>
<li><p><strong>condition_hidden_dim</strong> (<em>-</em>) – The number of channels in the hidden condition tensor.                 Default is None.</p></li>
<li><p><strong>t_condition_hidden_dim</strong> (<em>-</em>) – The number of channels in the hidden temporal condition tensor.                 Default is None.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.TemporalSpatialResidualNet.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network.html#TemporalSpatialResidualNet.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.TemporalSpatialResidualNet.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Return the output of the temporal spatial residual network.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<em>-</em>) – The temporal input tensor.</p></li>
<li><p><strong>x</strong> (<em>-</em>) – The input tensor.</p></li>
<li><p><strong>condition</strong> (<em>-</em>) – The condition tensor. Default is None.</p></li>
</ul>
</dd>
<dt class="field-even">Return type<span class="colon">:</span></dt>
<dd class="field-even"><p><span class="sphinx_autodoc_typehints-type"><code class="xref py py-class docutils literal notranslate"><span class="pre">Tensor</span></code></span></p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="dit">
<h2>DiT<a class="headerlink" href="#dit" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.neural_network.DiT">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.neural_network.</span></span><span class="sig-name descname"><span class="pre">DiT</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1152</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Diffusion model with a Transformer backbone.
This is the official implementation of Github repo:
<a class="reference external" href="https://github.com/facebookresearch/DiT/blob/main/models.py">https://github.com/facebookresearch/DiT/blob/main/models.py</a></p>
</dd>
<dt>Interfaces:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">forward</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">input_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">32</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1152</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">class_dropout_prob</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">0.1</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_classes</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1000</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize the DiT model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>input_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, defaults to 32) – The input size.</p></li>
<li><p><strong>patch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, defaults to 2) – The patch size.</p></li>
<li><p><strong>in_channels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, defaults to 4) – The number of input channels.</p></li>
<li><p><strong>hidden_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, defaults to 1152) – The hidden size.</p></li>
<li><p><strong>depth</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, defaults to 28) – The depth.</p></li>
<li><p><strong>num_heads</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, defaults to 16) – The number of attention heads.</p></li>
<li><p><strong>mlp_ratio</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, defaults to 4.0) – The hidden size of the MLP with respect to the hidden size of Attention.</p></li>
<li><p><strong>class_dropout_prob</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, defaults to 0.1) – The class dropout probability.</p></li>
<li><p><strong>num_classes</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>, defaults to 1000) – The number of classes.</p></li>
<li><p><strong>learn_sigma</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>, defaults to True) – Whether to learn sigma.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward pass of DiT.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – Tensor of diffusion timesteps.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – Tensor of spatial inputs (images or latent representations of images).</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict]</span></code>, optional) – The input condition, such as class labels.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT.forward_with_cfg">
<span class="sig-name descname"><span class="pre">forward_with_cfg</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">cfg_scale</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1.0</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT.forward_with_cfg"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT.forward_with_cfg" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward pass of DiT, but also batches the unconditional forward pass for classifier-free guidance.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – Tensor of diffusion timesteps.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – Tensor of spatial inputs (images or latent representations of images).</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict]</span></code>, optional) – The input condition, such as class labels.</p></li>
<li><p><strong>cfg_scale</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>, defaults to 1.0) – The scale for classifier-free guidance.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT.initialize_weights">
<span class="sig-name descname"><span class="pre">initialize_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT.initialize_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT.initialize_weights" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize the weights of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT.unpatchify">
<span class="sig-name descname"><span class="pre">unpatchify</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT.unpatchify"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT.unpatchify" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Unpatchify the input tensor.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input tensor.</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor.</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>imgs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>)</p>
</dd>
</dl>
<dl class="simple">
<dt>Shapes:</dt><dd><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>): (N, T, patch_size**2 * C)
imgs (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>): (N, H, W, C)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="dit1d">
<h2>DiT1D<a class="headerlink" href="#dit1d" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.neural_network.DiT1D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.neural_network.</span></span><span class="sig-name descname"><span class="pre">DiT1D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1152</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_embedder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT1D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT1D" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Transformer backbone for Diffusion model for 1D data.</p>
</dd>
<dt>Interfaces:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">forward</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT1D.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">token_size</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1152</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition_embedder</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT1D.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT1D.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize the DiT model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>in_channels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List[int],</span> <span class="pre">Tuple[int]]</span></code>) – The number of input channels, defaults to 4.</p></li>
<li><p><strong>hidden_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) – The hidden size of attention layer, defaults to 1152.</p></li>
<li><p><strong>depth</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) – The depth of transformer, defaults to 28.</p></li>
<li><p><strong>num_heads</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) – The number of attention heads, defaults to 16.</p></li>
<li><p><strong>mlp_ratio</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The hidden size of the MLP with respect to the hidden size of Attention, defaults to 4.0.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT1D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT1D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT1D.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward pass of DiT for 3D data.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – Tensor of diffusion timesteps.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – Tensor of inputs with spatial information (originally at t=0 it is tensor of videos or latent representations of videos).</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict]</span></code>, optional) – The input condition, such as class labels.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT1D.initialize_weights">
<span class="sig-name descname"><span class="pre">initialize_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT1D.initialize_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT1D.initialize_weights" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize the weights of the model.</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
<section id="dit2d">
<h2>DiT2D<a class="headerlink" href="#dit2d" title="Link to this heading"></a></h2>
<dl class="py attribute">
<dt class="sig sig-object py" id="grl.neural_network.DiT2D">
<span class="sig-prename descclassname"><span class="pre">grl.neural_network.</span></span><span class="sig-name descname"><span class="pre">DiT2D</span></span><a class="headerlink" href="#grl.neural_network.DiT2D" title="Link to this definition"></a></dt>
<dd><p>alias of <a class="reference internal" href="#grl.neural_network.DiT" title="grl.neural_network.transformers.dit.DiT"><code class="xref py py-class docutils literal notranslate"><span class="pre">DiT</span></code></a></p>
</dd></dl>

</section>
<section id="dit3d">
<h2>DiT3D<a class="headerlink" href="#dit3d" title="Link to this heading"></a></h2>
<dl class="py class">
<dt class="sig sig-object py" id="grl.neural_network.DiT3D">
<em class="property"><span class="pre">class</span><span class="w"> </span></em><span class="sig-prename descclassname"><span class="pre">grl.neural_network.</span></span><span class="sig-name descname"><span class="pre">DiT3D</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_block_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[10,</span> <span class="pre">32,</span> <span class="pre">32]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1152</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convolved</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT3D"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT3D" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Transformer backbone for Diffusion model for data of 3D shape.</p>
</dd>
<dt>Interfaces:</dt><dd><p><code class="docutils literal notranslate"><span class="pre">__init__</span></code>, <code class="docutils literal notranslate"><span class="pre">forward</span></code></p>
</dd>
</dl>
<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT3D.__init__">
<span class="sig-name descname"><span class="pre">__init__</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">patch_block_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">[10,</span> <span class="pre">32,</span> <span class="pre">32]</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">patch_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">2</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">in_channels</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">hidden_size</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">1152</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">depth</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">28</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">num_heads</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">16</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">mlp_ratio</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">4.0</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">learn_sigma</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">True</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">convolved</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">False</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT3D.__init__"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT3D.__init__" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize the DiT model.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>patch_block_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[List[int],</span> <span class="pre">Tuple[int]]</span></code>) – The size of patch block, defaults to [10, 32, 32].</p></li>
<li><p><strong>patch_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List[int],</span> <span class="pre">Tuple[int]]</span></code>) – The patch size of each token in attention layer, defaults to 2.</p></li>
<li><p><strong>in_channels</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[int,</span> <span class="pre">List[int],</span> <span class="pre">Tuple[int]]</span></code>) – The number of input channels, defaults to 4.</p></li>
<li><p><strong>hidden_size</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) – The hidden size of attention layer, defaults to 1152.</p></li>
<li><p><strong>depth</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) – The depth of transformer, defaults to 28.</p></li>
<li><p><strong>num_heads</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">int</span></code>) – The number of attention heads, defaults to 16.</p></li>
<li><p><strong>mlp_ratio</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">float</span></code>) – The hidden size of the MLP with respect to the hidden size of Attention, defaults to 4.0.</p></li>
<li><p><strong>learn_sigma</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to learn sigma, defaults to True.</p></li>
<li><p><strong>convolved</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">bool</span></code>) – Whether to use fully connected layer for all channels, defaults to False.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT3D.forward">
<span class="sig-name descname"><span class="pre">forward</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">t</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">x</span></span></em>, <em class="sig-param"><span class="n"><span class="pre">condition</span></span><span class="o"><span class="pre">=</span></span><span class="default_value"><span class="pre">None</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT3D.forward"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT3D.forward" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Forward pass of DiT for 3D data.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><ul class="simple">
<li><p><strong>t</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – Tensor of diffusion timesteps.</p></li>
<li><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – Tensor of inputs with spatial information (originally at t=0 it is tensor of videos or latent representations of videos).</p></li>
<li><p><strong>condition</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">Union[torch.Tensor,</span> <span class="pre">TensorDict]</span></code>, optional) – The input condition, such as class labels.</p></li>
</ul>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT3D.initialize_weights">
<span class="sig-name descname"><span class="pre">initialize_weights</span></span><span class="sig-paren">(</span><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT3D.initialize_weights"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT3D.initialize_weights" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Initialize the weights of the model.</p>
</dd>
</dl>
</dd></dl>

<dl class="py method">
<dt class="sig sig-object py" id="grl.neural_network.DiT3D.unpatchify">
<span class="sig-name descname"><span class="pre">unpatchify</span></span><span class="sig-paren">(</span><em class="sig-param"><span class="n"><span class="pre">x</span></span></em><span class="sig-paren">)</span><a class="reference internal" href="../../_modules/grl/neural_network/transformers/dit.html#DiT3D.unpatchify"><span class="viewcode-link"><span class="pre">[source]</span></span></a><a class="headerlink" href="#grl.neural_network.DiT3D.unpatchify" title="Link to this definition"></a></dt>
<dd><dl class="simple">
<dt>Overview:</dt><dd><p>Unpatchify the output tensor of attention layer.</p>
</dd>
</dl>
<dl class="field-list simple">
<dt class="field-odd">Parameters<span class="colon">:</span></dt>
<dd class="field-odd"><p><strong>x</strong> (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>) – The input tensor of shape (N, total_patches = T’ * H’ * W’, patch_size[0] * patch_size[1] * patch_size[2] * C)</p>
</dd>
<dt class="field-even">Returns<span class="colon">:</span></dt>
<dd class="field-even"><p>The output tensor of shape (N, T, C, H, W).</p>
</dd>
<dt class="field-odd">Return type<span class="colon">:</span></dt>
<dd class="field-odd"><p>x (<code class="xref py py-obj docutils literal notranslate"><span class="pre">torch.Tensor</span></code>)</p>
</dd>
</dl>
</dd></dl>

</dd></dl>

</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../generative_models/index.html" class="btn btn-neutral float-left" title="grl.generative_models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../numerical_methods/index.html" class="btn btn-neutral float-right" title="grl.numerical_methods" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, OpenDILab Contributors.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>